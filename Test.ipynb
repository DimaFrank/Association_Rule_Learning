{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbGffz8M2Mp60n7nXje4Ob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimaFrank/Association_Rule_Learning/blob/test/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZpkMk--GvcO",
        "outputId": "ca46189c-abac-4989-d1dd-88bc7b94b6c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=e6d516c0d62ddc4bc88a34157cb4221df1ed78a9b04198f7d3a2ef397c2d26ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_l8HsKQeGmCX"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import array, col, concat_ws, udf, array_remove, size, window, to_timestamp, date_format, concat, lit, collect_list, desc, sort_array, array_contains, array_intersect, array_union, concat_ws\n",
        "from pyspark.sql import SparkSession \n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resource:\n",
        "\n",
        "https://www.softwaretestinghelp.com/apriori-algorithm/"
      ],
      "metadata": {
        "id": "tAmi45tkbF7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"user_ct_test\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "jwy-ox42HN6u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TABLE-1\n",
        "rdd = spark.sparkContext.parallelize(\n",
        "    [Row(\"T1\", ['I1', 'I2', 'I3']),\n",
        "     Row(\"T2\", ['I4', 'I3', 'I2']),\n",
        "     Row(\"T3\", ['I4', 'I5']), \n",
        "     Row(\"T4\", ['I1', 'I2', 'I4']),\n",
        "     Row(\"T5\", ['I1', 'I2', 'I3', 'I5']),\n",
        "     Row(\"T6\", ['I1', 'I2', 'I3', 'I4']),   \n",
        "     ]\n",
        ")\n",
        "schema = StructType([\n",
        "    StructField(\"Tid\", StringType(), True),\n",
        "    StructField(\"Basket\", ArrayType(StringType(), True), True)\n",
        "])\n",
        "df = spark.createDataFrame(rdd, schema)\n",
        "df = df.withColumn('size',size(col('Basket')))\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_H7V1BuGuly",
        "outputId": "00ada795-c788-4034-b188-f4b665f7a42c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+----+\n",
            "|Tid|          Basket|size|\n",
            "+---+----------------+----+\n",
            "| T1|    [I1, I2, I3]|   3|\n",
            "| T2|    [I4, I3, I2]|   3|\n",
            "| T3|        [I4, I5]|   2|\n",
            "| T4|    [I1, I2, I4]|   3|\n",
            "| T5|[I1, I2, I3, I5]|   4|\n",
            "| T6|[I1, I2, I3, I4]|   4|\n",
            "+---+----------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df.select(\"Basket\",sort_array(\"Basket\",asc=True).alias('array_sorted'))\n",
        "df_test.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuNQ8UFwINDC",
        "outputId": "dd14dc9f-8f79-412b-bf94-54acb99e6ea4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+\n",
            "|          Basket|    array_sorted|\n",
            "+----------------+----------------+\n",
            "|    [I1, I2, I3]|    [I1, I2, I3]|\n",
            "|    [I4, I3, I2]|    [I2, I3, I4]|\n",
            "|        [I4, I5]|        [I4, I5]|\n",
            "|    [I1, I2, I4]|    [I1, I2, I4]|\n",
            "|[I1, I2, I3, I5]|[I1, I2, I3, I5]|\n",
            "|[I1, I2, I3, I4]|[I1, I2, I3, I4]|\n",
            "+----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_sup=3"
      ],
      "metadata": {
        "id": "JYvntACd0YbF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TABLE-2\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "F1 = (df_test\n",
        "           .withColumn(\"explode\", F.explode(\"array_sorted\"))\n",
        "           .groupBy(\"explode\")\n",
        "           .count()\n",
        "           .orderBy(F.desc(\"count\")))\n",
        "F1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdNmAafB0o5_",
        "outputId": "e122121d-c838-4e6d-88c2-83b0fb92aa1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|explode|count|\n",
            "+-------+-----+\n",
            "|     I2|    5|\n",
            "|     I4|    4|\n",
            "|     I3|    4|\n",
            "|     I1|    4|\n",
            "|     I5|    2|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TABLE-3\n",
        "F2 = F1.filter(col('count')>=min_sup)\n",
        "F2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5lvSZap0a1R",
        "outputId": "865c984a-c2c4-4144-e30c-a88404d030da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|explode|count|\n",
            "+-------+-----+\n",
            "|     I2|    5|\n",
            "|     I4|    4|\n",
            "|     I1|    4|\n",
            "|     I3|    4|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All possible combinations\n",
        "\n",
        "lst = [str(i.explode) for i in F2.select(\"explode\").collect()]\n",
        "print(lst)\n",
        "print('All Combinations: \\n')\n",
        "\n",
        "def create_possible_combinations(all_items, k):\n",
        "    # This functions gets a list of items and k, and returns all possible k-item combinations.\n",
        "    # all_items --> <list>\n",
        "    # k         --> <int>\n",
        "    res_tmp = set([])\n",
        "    for subset in itertools.combinations(all_items, k):       \n",
        "       res_tmp.add((subset))\n",
        "\n",
        "    res_lst = list(res_tmp)\n",
        "    result = [list(res_lst[i]) for i in range(len(res_lst))]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "create_possible_combinations(lst,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_7IP3gf1HGE",
        "outputId": "e6e69752-9f74-4caa-83ce-a79ce8fa5b84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I2', 'I4', 'I3', 'I1']\n",
            "All Combinations: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I2', 'I3'],\n",
              " ['I4', 'I1'],\n",
              " ['I2', 'I1'],\n",
              " ['I2', 'I4'],\n",
              " ['I4', 'I3'],\n",
              " ['I3', 'I1']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an empty DataFrame\n",
        "emp_RDD = spark.sparkContext.emptyRDD()\n",
        "columns1 = StructType([StructField('Item', ArrayType(StringType()), False),\n",
        "                       StructField('count', LongType(), False)])\n",
        "first_df = spark.createDataFrame(data=emp_RDD,\n",
        "                                         schema=columns1)\n",
        "\n",
        "\n",
        "for row in create_possible_combinations(lst,2):\n",
        "    # print(row)\n",
        "    res=df_test.withColumn(\"NewColumn\", F.array([F.lit(x) for x in row]))\n",
        "    res= res.select('array_sorted', size(array_intersect(res.array_sorted, res.NewColumn)).alias('Intersect'))\n",
        "    res = res.filter(col('Intersect')>=2).count()\n",
        "    # print(row, 'res=', res)\n",
        "    columns=['Item','count']\n",
        "    newRow = spark.createDataFrame([(row, res)], columns)\n",
        "    first_df = first_df.union(newRow).filter(col('count')>=min_sup)\n",
        "    \n",
        "\n",
        "first_df.show()  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "magqwgmw1ZGG",
        "outputId": "3dd4c2ea-97b1-4339-ecaf-2293f33833e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|    Item|count|\n",
            "+--------+-----+\n",
            "|[I2, I3]|    4|\n",
            "|[I2, I1]|    4|\n",
            "|[I2, I4]|    3|\n",
            "|[I3, I1]|    3|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in create_possible_combinations(lst,3):\n",
        "    # print(row)\n",
        "    res=df_test.withColumn(\"NewColumn\", F.array([F.lit(x) for x in row]))\n",
        "    res= res.select('array_sorted', size(array_intersect(res.array_sorted, res.NewColumn)).alias('Intersect'))\n",
        "    res = res.filter(col('Intersect')>=3).count()\n",
        "    # print(row, 'res=', res)\n",
        "    columns=['Item','count']\n",
        "    newRow = spark.createDataFrame([(row, res)], columns)\n",
        "    first_df = first_df.union(newRow).filter(col('count')>=min_sup)\n",
        "\n",
        "\n",
        "first_df.show()  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is4DWHZk1ZN1",
        "outputId": "3f15284b-041b-432f-e32f-5d255dde07d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|        Item|count|\n",
            "+------------+-----+\n",
            "|    [I2, I3]|    4|\n",
            "|    [I2, I1]|    4|\n",
            "|    [I2, I4]|    3|\n",
            "|    [I3, I1]|    3|\n",
            "|[I2, I3, I1]|    3|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation of algorithm"
      ],
      "metadata": {
        "id": "XKJ-rz6l6S32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "\n",
        "def build_support(sessions_data, items, min_support):\n",
        "\n",
        "    # sessions_data --> <DataFrame> Name of dataset contain sessions\n",
        "    # items         --> <ArrayType(StringType())> Column name that contain items\n",
        "    # min_support   --> <float> between 0 and 1\n",
        "\n",
        "\n",
        "    # Sort item set\n",
        "    data = sessions_data.select(items,sort_array(items,asc=True).alias('array'))\n",
        "\n",
        "    # Create F1 + Filter by min support:\n",
        "    F1 = (data.withColumn(\"explode\", F.explode(\"array\"))\n",
        "          .groupBy(\"explode\")\n",
        "          .count()\n",
        "          .orderBy(F.desc(\"count\"))).filter(col('count')>=min_support)\n",
        "\n",
        "    #Create all possible item combinations\n",
        "    lst = [str(i.explode) for i in F1.select(\"explode\").collect()]\n",
        "\n",
        "\n",
        "    # Create an empty DataFrame\n",
        "    emp_RDD = spark.sparkContext.emptyRDD()\n",
        "    columns1 = StructType([StructField('Item', ArrayType(StringType()), False),\n",
        "                          StructField('Support', LongType(), False)])\n",
        "    Support = spark.createDataFrame(data=emp_RDD,\n",
        "                                            schema=columns1)\n",
        "    \n",
        "    # Create Support\n",
        "    for k in range(1,4):\n",
        "        combinations = create_possible_combinations(lst,k)\n",
        "        for j in range(len(combinations)):\n",
        "            # print(combinations[j])\n",
        "            row = sorted(combinations[j])                   \n",
        "            res = sessions_data.withColumn(\"NewColumn\", F.array([F.lit(x) for x in row]))\n",
        "            res = res.select(items,'NewColumn', size(array_intersect(res.Basket, res.NewColumn)).alias('Intersect'))\n",
        "            res = res.filter(col('Intersect')>=k).count()\n",
        "            # res.show()\n",
        "            columns = ['Item','Support']\n",
        "            newRow = spark.createDataFrame([(row, res)], columns)\n",
        "            Support = Support.union(newRow).filter(col('Support')>=min_support)\n",
        "\n",
        "\n",
        "\n",
        "    return Support"
      ],
      "metadata": {
        "id": "-VTHhlzZf8DO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support = build_support(df, 'Basket', 3)\n",
        "support.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSvrFHtA8kEq",
        "outputId": "d0d9b432-0a49-472b-ade8-647f516131db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+\n",
            "|        Item|Support|\n",
            "+------------+-------+\n",
            "|        [I2]|      5|\n",
            "|        [I1]|      4|\n",
            "|        [I4]|      4|\n",
            "|        [I3]|      4|\n",
            "|    [I2, I3]|      4|\n",
            "|    [I1, I2]|      4|\n",
            "|    [I2, I4]|      3|\n",
            "|    [I1, I3]|      3|\n",
            "|[I1, I2, I3]|      3|\n",
            "+------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def association_rule_mining(support_table, confidence):\n",
        "\n",
        "    cross = support_table.select('Item').withColumnRenamed('Item', 'Item1')\\\n",
        "          .crossJoin(support.select('Item').withColumnRenamed('Item', 'Item2'))\\\n",
        "          .filter(col('Item1')!=col('Item2'))\n",
        "    cross2 = cross.select('*', sort_array(array_union(col('Item1'),col('Item2'))).alias('X'))\n",
        "    cross3 = cross2.join(support, on=[cross2.X==support.Item], how = 'left').drop(col('Item')).withColumnRenamed('Support', 'Support(X)')\n",
        "    cross4 = cross3.join(support, on=[cross3.Item1==support.Item], how = 'left').drop(col('Item')).withColumnRenamed('Support', 'Support(Y)')\n",
        "    cross5 = cross4.filter(col('Support(X)').isNotNull() & col('Support(Y)').isNotNull())\n",
        "    cross6 = cross5.select('*', (col('Support(X)')/col('Support(Y)')).alias('Confidence')).orderBy(col('Confidence').desc())\n",
        "    cross7 = cross6.withColumn(\"rule1\",concat_ws(\",\",col(\"Item1\"))).withColumn(\"rule2\",concat_ws(\",\",col(\"Item2\")))\n",
        "    cross8 = cross7.select('*', concat(lit('{'), cross7.rule1, lit('} ==> {'), cross7.rule2, lit('}')).alias('Rule')).drop(col('rule1')).drop(col('rule2'))\n",
        "    cross9 = cross8.filter(col('confidence')>=confidence)\n",
        "\n",
        "    return cross9.select('Rule','Confidence')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mjWOCEm6qw2q"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules = association_rule_mining(support,0.7)"
      ],
      "metadata": {
        "id": "8PMFjdolkAgM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules.show(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtuxhr9EkxiG",
        "outputId": "d491d80e-1008-45ff-bf50-c69c2723803e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|                Rule|Confidence|\n",
            "+--------------------+----------+\n",
            "|    {I3} ==> {I2,I3}|       1.0|\n",
            "|       {I3} ==> {I2}|       1.0|\n",
            "|       {I1} ==> {I2}|       1.0|\n",
            "|    {I2,I3} ==> {I3}|       1.0|\n",
            "|    {I1,I3} ==> {I3}|       1.0|\n",
            "|    {I1,I3} ==> {I1}|       1.0|\n",
            "|    {I2,I3} ==> {I2}|       1.0|\n",
            "|{I1,I3} ==> {I1,I...|       1.0|\n",
            "| {I1,I3} ==> {I1,I2}|       1.0|\n",
            "|    {I1,I2} ==> {I1}|       1.0|\n",
            "| {I1,I3} ==> {I2,I3}|       1.0|\n",
            "|    {I1,I3} ==> {I2}|       1.0|\n",
            "|    {I1,I2} ==> {I2}|       1.0|\n",
            "|{I1,I2,I3} ==> {I...|       1.0|\n",
            "|    {I1} ==> {I1,I2}|       1.0|\n",
            "|{I1,I2,I3} ==> {I...|       1.0|\n",
            "|    {I2,I4} ==> {I4}|       1.0|\n",
            "|{I1,I2,I3} ==> {I...|       1.0|\n",
            "| {I1,I2,I3} ==> {I3}|       1.0|\n",
            "|    {I2,I4} ==> {I2}|       1.0|\n",
            "| {I1,I2,I3} ==> {I1}|       1.0|\n",
            "| {I1,I2,I3} ==> {I2}|       1.0|\n",
            "|       {I2} ==> {I3}|       0.8|\n",
            "|    {I2} ==> {I1,I2}|       0.8|\n",
            "|    {I2} ==> {I2,I3}|       0.8|\n",
            "|       {I2} ==> {I1}|       0.8|\n",
            "|    {I1} ==> {I1,I3}|      0.75|\n",
            "|       {I4} ==> {I2}|      0.75|\n",
            "|       {I1} ==> {I3}|      0.75|\n",
            "|    {I3} ==> {I1,I3}|      0.75|\n",
            "|    {I2,I3} ==> {I1}|      0.75|\n",
            "| {I1} ==> {I1,I2,I3}|      0.75|\n",
            "|       {I3} ==> {I1}|      0.75|\n",
            "|    {I3} ==> {I1,I2}|      0.75|\n",
            "|{I1,I2} ==> {I1,I...|      0.75|\n",
            "|    {I1,I2} ==> {I3}|      0.75|\n",
            "|    {I1} ==> {I2,I3}|      0.75|\n",
            "| {I3} ==> {I1,I2,I3}|      0.75|\n",
            "|{I2,I3} ==> {I1,I...|      0.75|\n",
            "| {I2,I3} ==> {I1,I3}|      0.75|\n",
            "| {I1,I2} ==> {I1,I3}|      0.75|\n",
            "|    {I4} ==> {I2,I4}|      0.75|\n",
            "| {I2,I3} ==> {I1,I2}|      0.75|\n",
            "| {I1,I2} ==> {I2,I3}|      0.75|\n",
            "+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "support.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD6DEp_McrlO",
        "outputId": "513b7b8c-434a-4af9-c2db-1da0994f7ef7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+\n",
            "|        Item|Support|\n",
            "+------------+-------+\n",
            "|        [I2]|      5|\n",
            "|        [I1]|      4|\n",
            "|        [I4]|      4|\n",
            "|        [I3]|      4|\n",
            "|    [I2, I3]|      4|\n",
            "|    [I1, I2]|      4|\n",
            "|    [I2, I4]|      3|\n",
            "|    [I1, I3]|      3|\n",
            "|[I1, I2, I3]|      3|\n",
            "+------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pq0l1lRgeCNu"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}